## 2. チップレット/3次元実装技術

### 技術の意義

チップレット/3次元実装技術は、プロセスノード微細化の物理的・経済的限界を突破し、スーパーコンピュータの性能を飛躍的に向上させる革新的アプローチである。

**設計柔軟性とコスト最適化**：演算コア（先端プロセス）、I/Oダイ（成熟プロセス）、メモリを異なるプロセスノードで製造し、最適な組み合わせを実現。モノリシック大型チップに比べ歩留まりが向上し、開発コスト・製造コストを削減。マルチベンダーのチップレットを組み合わせることで、単一企業の技術リスクを分散できる。

**性能スケーラビリティ**：チップレットアーキテクチャにより、単一パッケージ内のコア数を大幅に増加（AMD EPYC 192コア等）。モノリシック設計では不可能な規模のシステムを実現し、スーパーコンピュータノードの演算能力を最大化する。

**メモリ帯域幅の劇的向上**：HBM（High Bandwidth Memory）の3D積層により、従来のDDRメモリ比で10倍以上の帯域幅を実現。AI/HPCワークロードにおけるメモリボトルネックを解消し、演算器の性能を最大限に引き出す。HBM4/5では10TB/s超の帯域幅が期待され、データ集約型計算の性能が飛躍的に向上する。

**電力効率とシステム統合**：演算器とメモリの物理的距離を短縮することで、データ転送の消費電力とレイテンシを削減。Processing-in-Memory（PIM）により、メモリ側での演算処理が可能となり、データ移動コストがさらに低減。先端パッケージング技術（CoWoS、EMIB、Foveros）により、システムの小型化と高密度実装を実現し、ラックあたりの演算密度が向上する。

**冷却技術の革新**：液冷・液浸冷却技術の導入により、150-200kW/ラック級の超高密度システムが実現可能に。空冷限界（10-15kW/ラック）を大きく超える電力密度でのシステム運用が可能となり、データセンターフットプリントあたりの性能が最大化される。

### 2.1 チップレットアーキテクチャ

#### 現状（2026年現在）

サーバー・HPC市場ではモノリシックチップからチップレットアーキテクチャへの移行が加速している。

**AMD**は2024年10月に第5世代EPYC 9005シリーズ（コードネーム：Turin）を発表。最大16個の4nm CCD（Core Compute Die）を搭載し、標準Zen 5版は128コア、高密度Zen 5c版は12個の3nm CCDで192コアを実現。従来の4象限配置から4列配置に変更し、より多くのチップレットを基板上に実装可能とした。同一SP5ソケットで後方互換性を維持しながら、DDR5-6400に対応。

**Intel**は第4世代Xeon Scalable（Sapphire Rapids）で4個のタイルを2.5D EMIB（Embedded Multi-die Interconnect Bridge）で接続するチップレット設計を採用。各タイルは400mm²のSoCで、演算コアとI/Oの両方を提供。興味深いことに、第5世代（Emerald Rapids）では2個の大型ダイ（各763mm²）に戻す設計変更を行い、歩留まりよりもL3キャッシュ容量（2.84倍）を優先した。

**TSMC**はInFO_LI（Integrated Fan-Out with Local Silicon Interconnect）技術を提供。ローカルシリコンインターコネクトを用いた2.5D接続で、大型で高価なインターポーザーの代わりに局所的なシリコンブリッジを使用。Appleが**M1 Ultra**および**M2 Ultra**で採用し、2つのダイ間に10,000本の接続で2.5TB/sの超低レイテンシ・高帯域幅チップ間通信を実現。IntelのEMIBと類似したアプローチながら、より高密度な接続を達成している。

**UCIe（Universal Chiplet Interconnect Express）**の標準化が急速に進展。2024年8月にUCIe 2.0、2025年8月にUCIe 3.0仕様がリリースされ、48/64 GT/sのデータレート（2.0比で2倍の帯域幅）をサポート。100社以上が参加し、2026-2028年の商用展開に向けて準備中。Ayar Labsは2025年に世界初のUCIe光インターコネクトチップレットを発表。

この設計手法により、演算コア、I/O、メモリコントローラを異なるプロセスノードで製造し、最適な組み合わせが可能になっている。

### 2.2 3次元積層技術

#### 現状（2026年現在）

3次元積層技術は、特にAI/HPC向けの高帯域幅メモリとチップ間接続において急速に成熟している。

**HBM（High Bandwidth Memory）市場**では、SK Hynix、Samsung、Micronの3社が激しく競争。2025年時点でSK Hynixが市場シェア53-62%でリード、36GB 12層HBM3Eの量産を開始。Micronが21%のシェアで追随し、12層HBM3Eのサンプリングを実施。Samsungは17-35%のシェアで、NVIDIAの12層HBM3E認証を取得し巻き返しを図る。HBM3Eの需給逼迫により、各社は2026年向け価格を約20%引き上げ、HBM4への移行準備を進めている。

**TSMCのCoWoS（Chip-on-Wafer-on-Substrate）**は、AI GPU向けパッケージングのボトルネックとなっている。月産能力を2024年末の3.5万枚から2026年末には12-13万枚へと3.7倍に拡大予定。しかし、2025-2026年の生産能力は既に完売状態で、NVIDIAが60%以上（2026年は80-85万枚）を確保。竹南のAP6、台南のAP8、嘉義のAP7施設が主力生産拠点。CoWoS-L（LSIブリッジ使用）とCoWoS-Sの両方式が展開されている。

**IntelのEMIB（Embedded Multi-Die Interconnect Bridge）とFoveros**も進化。2025年のGranite Rapidsで第2世代EMIBを採用し、マイクロバンプピッチを55μmから45μmに縮小。Foveros Direct 3Dは従来比16倍の3D接続密度を実現し、将来のClearwater Forestで採用予定。ニューメキシコ州のFab 9/11xでFoverosの量産を開始し、Apple、Qualcommなど外部顧客からも引き合いを受けている。

### 2.3 先端パッケージング技術

#### 現状（2026年現在）

先端パッケージング技術は、AI/HPC向けの大型・高密度実装と冷却技術の革新により急速に進化している。

**ファンアウトパネルレベルパッケージング（FOPLP）**市場は、2024年の25.3億ドルから2025年は30億ドル、2033年には117.3億ドル（CAGR 18.6%）へと急成長中。従来のウェハーレベルプロセスに比べ、300×300mm（高密度向けChip-Last）や600×600mm（低密度向けChip-First）パネルによる高いキャリア利用率と材料効率を実現。**ASE、Samsung、PTI**などの既存プレイヤーに加え、**Amkor、TSMC、Silicon Box**も参入。特にNVIDIAが、CoWoSの供給制約を回避するためGB200のFOPLP化を2026年から2025年に前倒しする計画を発表し、注目を集めている。

**システムインパッケージ（SiP）**では、ヘテロジニアス統合の重要性が増大。HD FO（High Density Fan-Out）、UHD FO、RDL（再配線層）、モールド/ガラスインターポーザーを活用した大型マルチダイSiPソリューションが展開され、よりファインなライン/スペース、縮小されたバンプピッチ、多層RDLが求められている。

**冷却技術**は、AI/HPCの電力密度増大（80-120kW/ラック）に対応するため、液冷が「実験段階から標準」へと移行。2025年時点で、**Direct-to-Chip（D2C）冷却**が最も一般的な方式となり、CPU/GPU/メモリに直接コールドプレートを搭載。**液浸冷却**は、80-100kW超のラック密度に有効で、単相浸漬は250W/cm²、二相浸漬は1500W/cm²以上の熱流束に対応。Microsoft、Google、Metaなどの大手クラウド事業者がAIクラスターで液冷を標準採用し、PUE（電力使用効率）を1.2以下に改善（空冷は1.4-1.6）。Dell、Lenovo、HPEは液冷サーバーを標準SKUとして提供開始。

### 2030年代への展望と今後の調査研究における課題

#### 技術発展の方向性

2030年代のチップレット/3次元実装技術は、スーパーコンピュータの性能向上とコスト削減の鍵となる。

**チップレットアーキテクチャ**では、異種プロセスノード混在チップレットが標準となり、演算コア（先端2nm/1.4nm）、I/Oダイ（成熟プロセス）、メモリコントローラを最適な組み合わせで構成可能となる。UCIe規格の成熟により、複数ベンダーのチップレットを組み合わせるオープンエコシステムが形成され、チップレットマーケットプレイスが出現する。特に重要なのは、チップレット間の光接続インターフェースの実用化で、電気配線の帯域幅・消費電力限界を突破する。ウェハー間直接接合（Wafer-to-Wafer Bonding）の量産化により、接続密度がさらに向上する。

**3次元積層技術**では、HBM4/5により10TB/s超のメモリ帯域幅が実現し、AI/HPCワークロードのメモリボトルネックが大幅に緩和される。10層以上の3D積層による超高集積システムが可能となり、演算器とメモリの距離がさらに短縮される。Processing-in-Memory（PIM）の標準化により、メモリ側での演算処理が一般化し、データ移動コストが削減される。再配線層（RDL）は1μm以下のピッチへと微細化し、チップレット間の高密度配線を実現する。

**先端パッケージング技術**では、パネルレベルパッケージング（PLP）の主流化によりコスト削減が進み、大型システムの経済性が向上する。埋め込みダイ技術によりチップがボードと一体化し、システムの小型化と高性能化が両立される。液浸冷却対応パッケージの普及により、超高電力密度プロセッサの実用化が可能となる。熱管理技術では、マイクロ流体冷却などの革新的手法が導入され、150-200kW/ラック級の超高密度実装に対応する。

#### 今後の調査研究における主要課題

**1. チップレット技術の実装戦略**
- UCIe等の標準規格の技術仕様詳細とスーパーコンピュータへの適用可能性評価
- チップレット設計ツールチェーン（EDAツール、検証環境）の成熟度と利用環境整備
- マルチベンダーチップレット統合の課題（電源管理、熱設計、信頼性）
- 日本独自のチップレット開発の可能性（Rapidus Chiplet Solutionsの活用）
- チップレット間光接続の実装課題とコスト分析

**2. HBMロードマップと調達戦略**
- HBM4/5の技術仕様、性能予測、量産時期の詳細調査
- SK Hynix、Samsung、Micronの供給能力と日本への供給優先度評価
- HBM調達における長期契約の必要性と価格動向予測
- Processing-in-Memory（PIM）の標準化動向と実効性能評価
- 国内半導体メーカー（キオクシア等）のHBM参入可能性

**3. 先端パッケージング技術と冷却**
- CoWoS、EMIB、Foverosの技術比較とスーパーコンピュータへの適用評価
- 3D積層における熱設計シミュレーションと冷却技術の最適化
- 国内パッケージング企業（イビデン、新光電気等）の技術力評価
- Rapidus Chiplet Solutions（セイコーエプソン千歳工場内）の技術開発計画と連携可能性
- 液冷・液浸冷却技術の導入コストとTCO分析
- 150-200kW/ラック級システムの熱設計指針策定

**4. システムインテグレーション課題**
- チップレット＋HBM＋光I/Oを統合したノードアーキテクチャの検討
- 電力配分最適化とピーク電力管理手法
- 信頼性評価手法と長期運用における故障率予測
- 再配線層（RDL）微細化に伴う製造コストとパフォーマンスのトレードオフ分析

### スーパーコンピュータへの影響
- ノード内演算性能の飛躍的向上
- メモリ帯域幅の大幅改善（HBM）
- 電力効率の向上とコスト削減
- 演算器とメモリの距離短縮によるレイテンシ削減
- 冷却技術の高度化要求
